{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfc8760b",
   "metadata": {},
   "source": [
    "## √Ålvaro S√°nchez de la Cruz, Marc Gil Arnau\n",
    "# Tarea 2\n",
    "# M√°quina de Vectores Soporte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a5bc9a",
   "metadata": {},
   "source": [
    "# √çndice de Contenidos\n",
    "\n",
    "1. [Configuraci√≥n Inicial y Preprocesamiento](#configuracion)\n",
    "2. [Secci√≥n I. Esquema Lineal](#seccion-i)\n",
    "    * 2.1. SVM Lineal Base: An√°lisis de coeficientes sin normalizar\n",
    "    * 2.2. Normalizaci√≥n y SVM Lineal Normalizado\n",
    "    * 2.3. Comparativa de Coeficientes: SVM vs Regresi√≥n Log√≠stica\n",
    "    * 2.4. Evaluaci√≥n de Prestaciones y Conclusiones del Esquema Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e77a579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# M√≥dulos de manipulaci√≥n de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import category_encoders as ce\n",
    "\n",
    "# M√≥dulos de persistencia (MLOps)\n",
    "import joblib\n",
    "\n",
    "# M√≥dulos de Scikit-Learn\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, \n",
    "    classification_report, \n",
    "    accuracy_score, \n",
    "    f1_score, \n",
    "    recall_score, \n",
    "    precision_score, \n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "# Configuraci√≥n de avisos\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e94cf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos\n",
    "comercio_df = pd.read_csv(\"G04.csv\")\n",
    "comercio_df = comercio_df.drop(\"ID\", axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d946d55",
   "metadata": {},
   "source": [
    "### Configuraci√≥n Inicial y Preprocesamiento la de Tarea 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee220f46",
   "metadata": {},
   "source": [
    "Dado que el An√°lisis Exploratorio de Datos (EDA) y la limpieza  se realizaron en la Tarea 1, en este notebook partimos de la carga del conjunto de datos original.\n",
    "\n",
    "Por lo que, para garantizar la consistencia de los resultados y que las comparaciones entre modelos sean rigurosas, aplicamos exactamente el mismo preprocesamiento definido en la tarea anterior. Esto incluye la codificaci√≥n de variables categ√≥ricas y la partici√≥n de los conjuntos de entrenamiento y test con la misma semilla aleatoria (random_state=0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4346493d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Warehouse_block</th>\n",
       "      <th>Mode_of_Shipment</th>\n",
       "      <th>Customer_care_calls</th>\n",
       "      <th>Customer_rating</th>\n",
       "      <th>Cost_of_the_Product</th>\n",
       "      <th>Prior_purchases</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Discount_offered</th>\n",
       "      <th>Weight_in_gms</th>\n",
       "      <th>Reached.on.Time_Y.N</th>\n",
       "      <th>Product_importance_Encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D</td>\n",
       "      <td>Flight</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>177</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>1233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>Flight</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>216</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>3088</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>Flight</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>183</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>3374</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Warehouse_block Mode_of_Shipment  Customer_care_calls  Customer_rating  \\\n",
       "0               D           Flight                    4                2   \n",
       "1               F           Flight                    4                5   \n",
       "2               A           Flight                    2                2   \n",
       "\n",
       "   Cost_of_the_Product  Prior_purchases  Gender  Discount_offered  \\\n",
       "0                  177                3       0                44   \n",
       "1                  216                2       1                59   \n",
       "2                  183                4       1                48   \n",
       "\n",
       "   Weight_in_gms  Reached.on.Time_Y.N  Product_importance_Encoded  \n",
       "0           1233                    1                           0  \n",
       "1           3088                    1                           0  \n",
       "2           3374                    1                           0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Copia y Mapeos Manuales\n",
    "comercio_copia = comercio_df.copy()\n",
    "\n",
    "# Mapeo de variable binaria (Gender)\n",
    "mapear_gender = {\"M\": 1, \"F\": 0}\n",
    "comercio_copia[\"Gender\"] = comercio_copia[\"Gender\"].map(mapear_gender).astype(\"Int64\")\n",
    "\n",
    "# Mapeo de variable ordinal (Product_importance)\n",
    "orden_importancia = {\"low\": 0, \"medium\": 1, \"high\": 2}\n",
    "comercio_copia[\"Product_importance_Encoded\"] = comercio_copia[\"Product_importance\"].map(orden_importancia).astype(\"Int64\")\n",
    "comercio_copia = comercio_copia.drop(columns=[\"Product_importance\"])\n",
    "\n",
    "display(comercio_copia.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64a266dc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones Dise√±o: (7699, 10)\n",
      "Dimensiones Test: (3300, 10)\n"
     ]
    }
   ],
   "source": [
    "# Partici√≥n y Codificaci√≥n final\n",
    "# Divisi√≥n X e y\n",
    "X = comercio_copia.drop(\"Reached.on.Time_Y.N\", axis=1)\n",
    "y = comercio_copia[\"Reached.on.Time_Y.N\"]\n",
    "\n",
    "# Partici√≥n Estratificada\n",
    "X_diseno, X_test, y_diseno, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)\n",
    "\n",
    "# Target Encoding\n",
    "encoder = ce.TargetEncoder(cols=[\"Warehouse_block\", \"Mode_of_Shipment\"], smoothing=0.2)\n",
    "encoder.fit(X_diseno, y_diseno)\n",
    "\n",
    "X_diseno_encoded = encoder.transform(X_diseno)\n",
    "X_test_encoded = encoder.transform(X_test)\n",
    "print(f\"Dimensiones Dise√±o: {X_diseno_encoded.shape}\")\n",
    "print(f\"Dimensiones Test: {X_test_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9867c7e5",
   "metadata": {},
   "source": [
    "Antes de comenzar con el dise√±o y entrenamiento de los modelos en las siguientes secciones, definiremos una funci√≥n de evaluaci√≥n. Esto nos permitir√° ir registrando las m√©tricas de cada modelo a medida que los generamos, facilitando la creaci√≥n de la tabla en la Secci√≥n III."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb40471d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario para almacenar los resultados de cada modelo\n",
    "resultados_comparativa = {}\n",
    "\n",
    "# Calculamos las m√©tricas y las guardamos en el diccionario\n",
    "def registrar_metricas(nombre_modelo, y_test_true, y_pred, y_prob):\n",
    "    metricas = {\n",
    "        'Accuracy': accuracy_score(y_test_true, y_pred),\n",
    "        'Precision': precision_score(y_test_true, y_pred, zero_division=0),\n",
    "        'Recall': recall_score(y_test_true, y_pred, zero_division=0),\n",
    "        'F1-Score': f1_score(y_test_true, y_pred, zero_division=0),\n",
    "        'AUC': roc_auc_score(y_test_true, y_prob)\n",
    "    }\n",
    "    resultados_comparativa[nombre_modelo] = metricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6232d5e4",
   "metadata": {},
   "source": [
    "## Secci√≥n I. Esquema Lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6603e6",
   "metadata": {},
   "source": [
    "### 1. SVM Lineal base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b9b3a5",
   "metadata": {},
   "source": [
    "Para abordar el dise√±o del esquema lineal, comenzamos con una aproximaci√≥n inicial utilizando todas las variables en su escala original. El objetivo de este experimento es verificar la sensibilidad de las M√°quinas de Vectores Soporte (SVM) a la dispersi√≥n de los datos. Entrenamos una SVM con kernel lineal, buscando el hiperpar√°metro de regularizaci√≥n C √≥ptimo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fef239e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando SVM Lineal (Datos Originales)...\n",
      "Mejor C: 0.001\n",
      "Mejor F1 (CV): 0.6218\n",
      "\n",
      "Reporte de Clasificaci√≥n (Datos Originales):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.22      0.29      1331\n",
      "           1       0.60      0.78      0.68      1969\n",
      "\n",
      "    accuracy                           0.55      3300\n",
      "   macro avg       0.50      0.50      0.48      3300\n",
      "weighted avg       0.52      0.55      0.52      3300\n",
      "\n",
      "\n",
      "Coeficientes obtenidos (Sin Normalizar):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coeficiente</th>\n",
       "      <th>Abs_Coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Product_importance_Encoded</td>\n",
       "      <td>0.004554</td>\n",
       "      <td>0.004554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Prior_purchases</td>\n",
       "      <td>-0.004194</td>\n",
       "      <td>0.004194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Customer_care_calls</td>\n",
       "      <td>-0.003145</td>\n",
       "      <td>0.003145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gender</td>\n",
       "      <td>0.002651</td>\n",
       "      <td>0.002651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cost_of_the_Product</td>\n",
       "      <td>-0.002383</td>\n",
       "      <td>0.002383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Customer_rating</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>0.001751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Discount_offered</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>0.000935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Weight_in_gms</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.000454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warehouse_block</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mode_of_Shipment</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Feature  Coeficiente  Abs_Coef\n",
       "9  Product_importance_Encoded     0.004554  0.004554\n",
       "5             Prior_purchases    -0.004194  0.004194\n",
       "2         Customer_care_calls    -0.003145  0.003145\n",
       "6                      Gender     0.002651  0.002651\n",
       "4         Cost_of_the_Product    -0.002383  0.002383\n",
       "3             Customer_rating     0.001751  0.001751\n",
       "7            Discount_offered     0.000935  0.000935\n",
       "8               Weight_in_gms     0.000454  0.000454\n",
       "0             Warehouse_block     0.000025  0.000025\n",
       "1            Mode_of_Shipment    -0.000005  0.000005"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Configuraci√≥n del espacio de b√∫squeda\n",
    "param_grid_svm = {'C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "\n",
    "# Definici√≥n del modelo (limitamos iteraciones para evitar bloqueos)\n",
    "svm_linear = SVC(kernel='linear', random_state=0, probability=True, max_iter=2000)\n",
    "\n",
    "# GridSearch con Validaci√≥n Cruzada\n",
    "grid_search_svm = GridSearchCV(\n",
    "    estimator=svm_linear,\n",
    "    param_grid=param_grid_svm,\n",
    "    scoring='f1',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Entrenando SVM Lineal (Datos Originales)...\")\n",
    "grid_search_svm.fit(X_diseno_encoded, y_diseno)\n",
    "\n",
    "# Resultados\n",
    "best_svm_linear = grid_search_svm.best_estimator_\n",
    "print(f\"Mejor C: {grid_search_svm.best_params_['C']}\")\n",
    "print(f\"Mejor F1 (CV): {grid_search_svm.best_score_:.4f}\")\n",
    "\n",
    "# Evaluamos en Test\n",
    "y_pred_svm = best_svm_linear.predict(X_test_encoded)\n",
    "print(\"\\nReporte de Clasificaci√≥n (Datos Originales):\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "# An√°lisis de Coeficientes\n",
    "coef_svm = pd.DataFrame({\n",
    "    'Feature': X_diseno_encoded.columns,\n",
    "    'Coeficiente': best_svm_linear.coef_[0],\n",
    "    'Abs_Coef': np.abs(best_svm_linear.coef_[0])\n",
    "}).sort_values(by='Abs_Coef', ascending=False)\n",
    "\n",
    "print(\"\\nCoeficientes obtenidos (Sin Normalizar):\")\n",
    "display(coef_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4964eb3",
   "metadata": {},
   "source": [
    "Los resultados del modelo base confirman que la disparidad de escalas afecta negativamente al aprendizaje. Se observa un Accuracy bajo (55%) y unos coeficientes distorsionados, las variables con magnitudes num√©ricas grandes (como Weight_in_gms) reciben pesos extremadamente peque√±os para compensar su escala, mientras que el modelo no logra converger adecuadamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fab310",
   "metadata": {},
   "source": [
    "### Normalizaci√≥n y SVM Lineal Normalizado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78585d80",
   "metadata": {},
   "source": [
    "Como las SVM se basan en distancias para definir el margen, es necesario normalizar los datos. Vamos a aplicar StandardScaler para estandarizar las variables (media 0, desviaci√≥n 1) y reentrenamos el modelo lineal en este nuevo espacio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9444a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Warehouse_block</th>\n",
       "      <th>Mode_of_Shipment</th>\n",
       "      <th>Customer_care_calls</th>\n",
       "      <th>Customer_rating</th>\n",
       "      <th>Cost_of_the_Product</th>\n",
       "      <th>Prior_purchases</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Discount_offered</th>\n",
       "      <th>Weight_in_gms</th>\n",
       "      <th>Product_importance_Encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7699.00</td>\n",
       "      <td>7699.00</td>\n",
       "      <td>7699.00</td>\n",
       "      <td>7699.00</td>\n",
       "      <td>7699.00</td>\n",
       "      <td>7699.00</td>\n",
       "      <td>7699.0</td>\n",
       "      <td>7699.00</td>\n",
       "      <td>7699.00</td>\n",
       "      <td>7699.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.47</td>\n",
       "      <td>-2.10</td>\n",
       "      <td>-1.81</td>\n",
       "      <td>-1.41</td>\n",
       "      <td>-2.36</td>\n",
       "      <td>-1.03</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.76</td>\n",
       "      <td>-1.61</td>\n",
       "      <td>-0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.15</td>\n",
       "      <td>0.16</td>\n",
       "      <td>-0.94</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>-1.10</td>\n",
       "      <td>-0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.16</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.06</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.06</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2.58</td>\n",
       "      <td>1.42</td>\n",
       "      <td>2.07</td>\n",
       "      <td>4.21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.22</td>\n",
       "      <td>2.30</td>\n",
       "      <td>2.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Warehouse_block  Mode_of_Shipment  Customer_care_calls  \\\n",
       "count          7699.00           7699.00              7699.00   \n",
       "mean              0.00              0.00                -0.00   \n",
       "std               1.00              1.00                 1.00   \n",
       "min              -1.47             -2.10                -1.81   \n",
       "25%              -1.15              0.16                -0.94   \n",
       "50%               0.48              0.16                -0.06   \n",
       "75%               1.06              0.16                 0.82   \n",
       "max               1.06              1.35                 2.58   \n",
       "\n",
       "       Customer_rating  Cost_of_the_Product  Prior_purchases  Gender  \\\n",
       "count          7699.00              7699.00          7699.00  7699.0   \n",
       "mean             -0.00                -0.00            -0.00     0.0   \n",
       "std               1.00                 1.00             1.00     1.0   \n",
       "min              -1.41                -2.36            -1.03    -1.0   \n",
       "25%              -0.70                -0.85            -0.37    -1.0   \n",
       "50%               0.01                 0.08            -0.37     1.0   \n",
       "75%               0.71                 0.85             0.28     1.0   \n",
       "max               1.42                 2.07             4.21     1.0   \n",
       "\n",
       "       Discount_offered  Weight_in_gms  Product_importance_Encoded  \n",
       "count           7699.00        7699.00                     7699.00  \n",
       "mean               0.00           0.00                        0.00  \n",
       "std                1.00           1.00                        1.00  \n",
       "min               -0.76          -1.61                       -0.94  \n",
       "25%               -0.58          -1.10                       -0.94  \n",
       "50%               -0.39           0.32                        0.62  \n",
       "75%               -0.20           0.87                        0.62  \n",
       "max                3.22           2.30                        2.18  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Escogemos las columnas n√∫mericas\n",
    "num_col = X_diseno_encoded.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "\n",
    "# Creamos y ajustamos el scaler solo con el conjunto de dise√±o\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_diseno_encoded[num_col])\n",
    "\n",
    "# Transformamos y asignamos los nuevos valores a ambos conjuntos\n",
    "X_diseno_encoded[num_col] = scaler.transform(X_diseno_encoded[num_col])\n",
    "X_test_encoded[num_col] = scaler.transform(X_test_encoded[num_col])\n",
    "\n",
    "X_diseno_encoded.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92138fe",
   "metadata": {},
   "source": [
    "Una vez corregida la escala, entrenamos de nuevo el SVM con kernel lineal. Mantenemos la misma estrategia de b√∫squeda de hiperpar√°metros (GridSearch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eaff937e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando entrenamiento SVM Lineal con datos normalizados...\n",
      "Mejor regularizaci√≥n encontrada (C): 0.001\n",
      "Mejor F1 medio en Validaci√≥n Cruzada: 0.7149\n",
      "\n",
      "Reporte de Clasificaci√≥n (SVM Normalizada):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.69      0.63      1331\n",
      "           1       0.76      0.66      0.70      1969\n",
      "\n",
      "    accuracy                           0.67      3300\n",
      "   macro avg       0.67      0.67      0.67      3300\n",
      "weighted avg       0.69      0.67      0.67      3300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Configuraci√≥n del GridSearch\n",
    "grid_search_svm_norm = GridSearchCV(\n",
    "    estimator=SVC(kernel='linear', random_state=0, probability=True),\n",
    "    param_grid={'C': [0.001, 0.01, 0.1, 1, 10]},\n",
    "    scoring='f1',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Iniciando entrenamiento SVM Lineal con datos normalizados...\")\n",
    "grid_search_svm_norm.fit(X_diseno_encoded, y_diseno)\n",
    "\n",
    "# Resultados\n",
    "best_svm_norm = grid_search_svm_norm.best_estimator_\n",
    "best_C_norm = grid_search_svm_norm.best_params_['C']\n",
    "\n",
    "print(f\"Mejor regularizaci√≥n encontrada (C): {best_C_norm}\")\n",
    "print(f\"Mejor F1 medio en Validaci√≥n Cruzada: {grid_search_svm_norm.best_score_:.4f}\")\n",
    "\n",
    "# Evaluamos en Test\n",
    "y_pred_norm = best_svm_norm.predict(X_test_encoded)\n",
    "y_prob_norm = best_svm_norm.predict_proba(X_test_encoded)[:, 1]\n",
    "\n",
    "# Mostramos el reporte\n",
    "print(\"\\nReporte de Clasificaci√≥n (SVM Normalizada):\")\n",
    "print(classification_report(y_test, y_pred_norm))\n",
    "\n",
    "# Guardamos m√©tricas para la secci√≥n final\n",
    "metricas_svm_norm = {\n",
    "    'Accuracy': accuracy_score(y_test, y_pred_norm),\n",
    "    'Precision': precision_score(y_test, y_pred_norm, zero_division=0),\n",
    "    'Recall': recall_score(y_test, y_pred_norm, zero_division=0),\n",
    "    'F1-Score': f1_score(y_test, y_pred_norm, zero_division=0),\n",
    "    'AUC': roc_auc_score(y_test, y_prob_norm)\n",
    "}\n",
    "resultados_tarea2 = {} \n",
    "resultados_tarea2[\"SVM Lineal\"] = metricas_svm_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de07c94",
   "metadata": {},
   "source": [
    "La normalizaci√≥n ha tenido un gran impacto en el rendimiento del modelo subiendo el Accuracy del 55% al 67%. Adem√°s, el modelo ahora equilibra mejor la detecci√≥n de ambas clases (Recall 0.69 en clase 0 y Precision 0.76 en clase 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2f8108",
   "metadata": {},
   "source": [
    "### Comparativa de Coeficientes: SVM vs Regresi√≥n Log√≠stica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1fdca4",
   "metadata": {},
   "source": [
    "Una vez estabilizado el modelo SVM, vamos a analizar qu√© variables son las m√°s relevantes para la clasificaci√≥n, comparando los coeficientes obtenidos por la SVM con los de un modelo de Regresi√≥n Log√≠stica.\n",
    "\n",
    "En lugar de reentrenar el modelo log√≠stico desde cero, vamos a cargar con joblib el modelo con regularizaci√≥n L2 entrenado en la Tarea 1. Esto nos permite comparar ambos algoritmos sobre el mismo conjunto completo de variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ec0922b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking de Importancia: SVM vs Regresi√≥n Log√≠stica\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Coef_SVM</th>\n",
       "      <th>Coef_RL</th>\n",
       "      <th>Abs_Coef_SVM</th>\n",
       "      <th>Abs_Coef_RL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Weight_in_gms</td>\n",
       "      <td>-0.573762</td>\n",
       "      <td>-0.295232</td>\n",
       "      <td>0.573762</td>\n",
       "      <td>0.295232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Discount_offered</td>\n",
       "      <td>0.394588</td>\n",
       "      <td>0.523947</td>\n",
       "      <td>0.394588</td>\n",
       "      <td>0.523947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Prior_purchases</td>\n",
       "      <td>-0.081003</td>\n",
       "      <td>-0.082220</td>\n",
       "      <td>0.081003</td>\n",
       "      <td>0.082220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Customer_care_calls</td>\n",
       "      <td>-0.080558</td>\n",
       "      <td>-0.094190</td>\n",
       "      <td>0.080558</td>\n",
       "      <td>0.094190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Customer_rating</td>\n",
       "      <td>0.069029</td>\n",
       "      <td>0.033330</td>\n",
       "      <td>0.069029</td>\n",
       "      <td>0.033330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Product_importance_Encoded</td>\n",
       "      <td>0.034054</td>\n",
       "      <td>0.033080</td>\n",
       "      <td>0.034054</td>\n",
       "      <td>0.033080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gender</td>\n",
       "      <td>0.029994</td>\n",
       "      <td>0.014284</td>\n",
       "      <td>0.029994</td>\n",
       "      <td>0.014284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mode_of_Shipment</td>\n",
       "      <td>0.028303</td>\n",
       "      <td>0.008534</td>\n",
       "      <td>0.028303</td>\n",
       "      <td>0.008534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cost_of_the_Product</td>\n",
       "      <td>0.027584</td>\n",
       "      <td>-0.077290</td>\n",
       "      <td>0.027584</td>\n",
       "      <td>0.077290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warehouse_block</td>\n",
       "      <td>0.005058</td>\n",
       "      <td>0.005877</td>\n",
       "      <td>0.005058</td>\n",
       "      <td>0.005877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Variable  Coef_SVM   Coef_RL  Abs_Coef_SVM  Abs_Coef_RL\n",
       "8               Weight_in_gms -0.573762 -0.295232      0.573762     0.295232\n",
       "7            Discount_offered  0.394588  0.523947      0.394588     0.523947\n",
       "5             Prior_purchases -0.081003 -0.082220      0.081003     0.082220\n",
       "2         Customer_care_calls -0.080558 -0.094190      0.080558     0.094190\n",
       "3             Customer_rating  0.069029  0.033330      0.069029     0.033330\n",
       "9  Product_importance_Encoded  0.034054  0.033080      0.034054     0.033080\n",
       "6                      Gender  0.029994  0.014284      0.029994     0.014284\n",
       "1            Mode_of_Shipment  0.028303  0.008534      0.028303     0.008534\n",
       "4         Cost_of_the_Product  0.027584 -0.077290      0.027584     0.077290\n",
       "0             Warehouse_block  0.005058  0.005877      0.005058     0.005877"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cargamos de modelo de Regresi√≥n Log√≠stica\n",
    "rl_model_cargado = joblib.load('modelo_rl_l2_completo.joblib')\n",
    "\n",
    "# Tabla comparativa de coeficientes\n",
    "comparativa = pd.DataFrame({\n",
    "    'Variable': X_diseno_encoded.columns,\n",
    "    'Coef_SVM': best_svm_norm.coef_[0],\n",
    "    'Coef_RL': rl_model_cargado.coef_[0],\n",
    "    'Abs_Coef_SVM': np.abs(best_svm_norm.coef_[0]), \n",
    "    'Abs_Coef_RL': np.abs(rl_model_cargado.coef_[0])\n",
    "}).sort_values(by='Abs_Coef_SVM', ascending=False)\n",
    "\n",
    "print(\"Ranking de Importancia: SVM vs Regresi√≥n Log√≠stica\")\n",
    "display(comparativa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab843ddf",
   "metadata": {},
   "source": [
    "Los resultados muestran una consistencia entre ambos modelos. Tanto la SVM como la Regresi√≥n Log√≠stica identifican a Weight_in_gms (Coeficiente negativo) y Discount_offered (Coeficiente positivo) como las variables determinantes, asign√°ndoles pesos significativamente mayores que al resto.\n",
    "\n",
    "Esta coincidencia confirma que, bajo linealidad, la clasificaci√≥n depende casi exclusivamente de la interacci√≥n entre el peso y el descuento, siendo el resto de variables informaci√≥n redundante o ruido."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556fb30e",
   "metadata": {},
   "source": [
    "### Evaluaci√≥n de Prestaciones y Conclusiones del Esquema Lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0a40e8",
   "metadata": {},
   "source": [
    "## Dudas\n",
    "- En la secci√≥n I tenemos que volver a cargar y hacer los cambios de preprocesamiento o podemos hacer un checkpoint despues del preprocesamiento y trabajar a partir de ese dataset?\n",
    "- Que regresor usar?\n",
    "- Hemos ido comentando las m√©tricas bloque a bloque, al final pides comparar prestaciones lo vuelvo a hacer, cambio los comentarios de los bloques anteriores?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4ec565",
   "metadata": {},
   "source": [
    "### Secci√≥n II. Esquema no Lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599dfbc8",
   "metadata": {},
   "source": [
    "Explique si considera razonable abordar el dise√±o de una SVM con un kernel no lineal.\n",
    "\n",
    "Consideramos razonable usar un kernel no lineal para hacer una SVM ya que hemos demostrado que nuestros datos no son linealmente separables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c55529",
   "metadata": {},
   "source": [
    "Discuta la necesidad o no de normalizar las caracter√≠sticas antes de realizar el entrenamiento del\n",
    "modelo.\n",
    "\n",
    "Como las SVM se basan en calcular distancias, es necesaria la normalizaci√≥n, sin esta, las variables con un rango m√°s amplio tendr√≠an m√°s relevancia en la distancia para calcular el margen, haciendo que este estuviese sesgado hacia ellas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3821e5",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d997d8e2",
   "metadata": {},
   "source": [
    "Donde C es un par√°metro positivo. El par√°metro C controla el peso dado al error de clasificaci√≥n en el entrenamiento (medido por la suma) y a la complejidad (medida por la norma del vector de pesos) .\n",
    "\n",
    "Un alto valor de C obliga a tener pocos par√°metros de holgura diferentes de cero (o con valores grandes) en la soluci√≥n final.\n",
    "\n",
    "C m√°s grande: m√°rgenes m√°s peque√±os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29148af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, make_scorer, classification_report\n",
    ")\n",
    "\n",
    "# --- 1. Carga de Datos ---\n",
    "# Asumo que X_diseno_encoded.values ya est√°n escalados/normalizados\n",
    "X_train = X_diseno_encoded.values\n",
    "X_test = X_test_encoded.values\n",
    "y_train = y_diseno.values\n",
    "y_test = y_test\n",
    "\n",
    "# --- 2. Definici√≥n de las 5 Figuras de M√©rito (Scorers) ---\n",
    "# Usamos make_scorer para integrar las funciones de m√©trica en GridSearchCV\n",
    "f1_scorer = make_scorer(f1_score) \n",
    "auc_scorer = make_scorer(roc_auc_score, needs_proba=True)\n",
    "precision_scorer = make_scorer(precision_score)\n",
    "recall_scorer = make_scorer(recall_score)\n",
    "accuracy_scorer = make_scorer(accuracy_score)\n",
    "\n",
    "scoring_metrics = {\n",
    "    'accuracy': accuracy_scorer,\n",
    "    'f1_pos': f1_scorer,\n",
    "    'precision_pos': precision_scorer,\n",
    "    'recall_pos': recall_scorer,\n",
    "    'auc': auc_scorer\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f09f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando b√∫squeda en cuadr√≠cula con pesos de clase balanceados...\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Pipeline (¬°SIN ESCALADO, ya que los datos est√°n normalizados!) ---\n",
    "# SVC requiere probability=True para poder calcular AUC (roc_auc_score)\n",
    "pipeline_svm_balanced = Pipeline([\n",
    "    # Si tus datos ya est√°n normalizados, mantenemos solo el SVC\n",
    "    ('svc', SVC(random_state=0, probability=True, class_weight='balanced')) \n",
    "    # ^^^ ESTE ES EL CAMBIO CLAVE ^^^\n",
    "])\n",
    "\n",
    "# --- 4. Definici√≥n de la Cuadr√≠cula de Hiperpar√°metros (Explorando Kernels) ---\n",
    "# Exploramos RBF (Gaussiano) y Polin√≥mico (Poly), que son los no lineales\n",
    "param_grid = [\n",
    "    # Kernel RBF (Gaussiano)\n",
    "    {\n",
    "        'svc__kernel': ['rbf'],\n",
    "        'svc__C': [0.1, 1, 10],            # Par√°metro de regularizaci√≥n\n",
    "        'svc__gamma': [0.01, 0.1, 1]       # Par√°metro del kernel RBF (Controla la influencia)\n",
    "    },\n",
    "    # Kernel Polin√≥mico (Poly)\n",
    "    {\n",
    "        'svc__kernel': ['poly'],\n",
    "        'svc__C': [0.1, 1, 10],\n",
    "        'svc__degree': [2, 3],             # Grado del polinomio\n",
    "        'svc__gamma': ['scale']\n",
    "    }\n",
    "]\n",
    "\n",
    "# --- 5. Inicializaci√≥n y Entrenamiento de GridSearchCV ---\n",
    "# 'refit='f1_pos' selecciona el mejor modelo seg√∫n el F1-Score (nuestra m√©trica de selecci√≥n)\n",
    "grid_search_balanced = GridSearchCV(\n",
    "    estimator=pipeline_svm_balanced,\n",
    "    param_grid=param_grid,  # Usa la misma cuadr√≠cula de b√∫squeda de C y gamma\n",
    "    scoring=scoring_metrics,\n",
    "    refit='f1_pos', \n",
    "    cv=5, \n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Iniciando b√∫squeda en cuadr√≠cula con pesos de clase balanceados...\")\n",
    "grid_search_balanced.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3154f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. Resultados y Elecci√≥n del Mejor Modelo ---\n",
    "df_res = pd.DataFrame(grid_search_balanced.cv_results_)\n",
    "\n",
    "# Filtramos las m√©tricas de inter√©s para visualizaci√≥n\n",
    "df_metrics = df_res[[\n",
    "    'params', \n",
    "    'mean_test_f1_pos', \n",
    "    'mean_test_auc', \n",
    "    'mean_test_accuracy', \n",
    "    'mean_test_precision_pos', \n",
    "    'mean_test_recall_pos'\n",
    "]]\n",
    "\n",
    "best_index = grid_search_balanced.best_index_\n",
    "best_result = df_metrics.iloc[best_index]\n",
    "\n",
    "best_params = grid_search_balanced.best_params_\n",
    "best_kernel = best_params['svc__kernel']\n",
    "\n",
    "print(\"\\n=========================================================\")\n",
    "print(\"            üèÜ Resultados de la B√∫squeda de Kernel         \")\n",
    "print(\"=========================================================\")\n",
    "print(\"MEJOR KERNEL Y PAR√ÅMETROS:\", best_params)\n",
    "print(f\"M√âTRICA DE SELECCI√ìN (F1-Score) en CV: {best_result['mean_test_f1_pos']:.4f}\")\n",
    "print(\"---------------------------------------------------------\")\n",
    "\n",
    "# --- 7. Gr√°fica de la evoluci√≥n de la m√©trica de m√©rito principal ---\n",
    "# La representaci√≥n de la evoluci√≥n se hace a trav√©s de las diferentes combinaciones probadas\n",
    "plt.figure(figsize=(14, 6))\n",
    "# 'mean_test_f1_pos' es el F1-Score medio en el conjunto de validaci√≥n (CV)\n",
    "plt.plot(df_res.index, df_res['mean_test_f1_pos'], marker='o', linestyle='-', color='indigo')\n",
    "plt.title(f\"Evoluci√≥n del F1-Score (M√©trica Adecuada) en Validaci√≥n Cruzada por Arquitectura\")\n",
    "plt.xlabel(\"Configuraci√≥n de Hiperpar√°metros (√çndice de la Cuadr√≠cula)\")\n",
    "plt.ylabel(\"F1-Score Medio de Validaci√≥n (CV)\")\n",
    "\n",
    "# Configuramos las etiquetas del eje X con el kernel y el par√°metro C\n",
    "labels = []\n",
    "for p in df_res['params']:\n",
    "    if p['svc__kernel'] == 'rbf':\n",
    "        labels.append(f\"RBF, C={p['svc__C']}, Œ≥={p['svc__gamma']}\")\n",
    "    elif p['svc__kernel'] == 'poly':\n",
    "        labels.append(f\"Poly, C={p['svc__C']}, d={p['svc__degree']}\")\n",
    "    else:\n",
    "        labels.append(str(p))\n",
    "\n",
    "plt.xticks(df_res.index, labels, rotation=45, ha='right')\n",
    "plt.grid(axis='y', linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nArquitectura Elegida: La combinaci√≥n de kernel e hiperpar√°metros con el mayor F1-Score medio en CV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efe031f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 8. Evaluaci√≥n Final en el Conjunto de PRUEBA (Test) ---\n",
    "mejor_modelo_svm = grid_search_balanced.best_estimator_\n",
    "\n",
    "# Predicciones\n",
    "y_prob_multi = mejor_modelo_svm.predict_proba(X_test)[:, 1]\n",
    "y_pred_multi = mejor_modelo_svm.predict(X_test)\n",
    "\n",
    "# M√©tricas finales\n",
    "final_metrics = {\n",
    "    \"accuracy\": accuracy_score(y_test, y_pred_multi),\n",
    "    \"precision_pos\": precision_score(y_test, y_pred_multi),\n",
    "    \"recall_pos\": recall_score(y_test, y_pred_multi),\n",
    "    \"f1_pos\": f1_score(y_test, y_pred_multi),\n",
    "    \"auc\": roc_auc_score(y_test, y_prob_multi)\n",
    "}\n",
    "\n",
    "print(\"\\n=========================================================\")\n",
    "print(f\"       ‚úÖ Evaluaci√≥n FINAL del Mejor Modelo ({best_kernel.upper()})        \")\n",
    "print(\"=========================================================\")\n",
    "print(\"M√âTRICAS EN TEST:\", final_metrics)\n",
    "print(\"\\nReporte de Clasificaci√≥n en Test:\")\n",
    "print(classification_report(y_test, y_pred_multi))\n",
    "\n",
    "# Aqu√≠ ir√≠a tu funci√≥n para guardar resultados\n",
    "# registrar_metricas(\"6. SVM No Lineal\", y_test, y_pred_multi, y_prob_multi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c1a55d",
   "metadata": {},
   "source": [
    "El modelo est√° completamente sesgado hacia los paquetes que llegan tarde"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0321a915",
   "metadata": {},
   "source": [
    "Wrapper con SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7a0ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, classification_report, make_scorer\n",
    ")\n",
    "from IPython.display import display\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. PREPARACI√ìN DE DATOS Y M√âTRICAS\n",
    "# ==============================================================================\n",
    "# Asumimos que X_train, X_test, y_train, y_test est√°n cargados y listos.\n",
    "# X_train = X_diseno_encoded.values\n",
    "# X_test = X_test_encoded.values\n",
    "# y_train = y_diseno.values\n",
    "# y_test = y_test.values\n",
    "\n",
    "# Define las 5 m√©tricas (scorers)\n",
    "f1_scorer = make_scorer(f1_score) \n",
    "auc_scorer = make_scorer(roc_auc_score, needs_proba=True)\n",
    "scoring_metrics = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'f1_pos': f1_scorer,\n",
    "    'precision_pos': make_scorer(precision_score),\n",
    "    'recall_pos': make_scorer(recall_score),\n",
    "    'auc': auc_scorer\n",
    "}\n",
    "\n",
    "# Recuperamos los mejores par√°metros del GridSearch BALANCEADO (Secci√≥n II)\n",
    "# *** ASEG√öRATE DE QUE grid_search_balanced EST√â DEFINIDO CON EL MEJOR MODELO RBF ***\n",
    "try:\n",
    "    best_params = grid_search_balanced.best_params_\n",
    "except NameError:\n",
    "    print(\"ADVERTENCIA: Usando par√°metros por defecto. ¬°Aseg√∫rate de ejecutar la Secci√≥n II (balanceada)!\")\n",
    "    # Par√°metros de ejemplo si grid_search_balanced no est√° definido\n",
    "    best_params = {'svc__kernel': 'rbf', 'svc__C': 1, 'svc__gamma': 0.1} \n",
    "\n",
    "# ==============================================================================\n",
    "# 2. SELECCI√ìN DE CARACTER√çSTICAS (RFE con LinearSVC)\n",
    "# ==============================================================================\n",
    "\n",
    "# Estimador base que S√ç tiene coef_ para RFE (SVM Lineal)\n",
    "# Usamos un Pipeline para manejar el escalado dentro del RFE si fuera necesario\n",
    "rfe_base_estimator = Pipeline([\n",
    "    ('scaler', StandardScaler()), # Incluimos StandardScaler por si RFE lo requiere internamente\n",
    "    ('lsvc', LinearSVC(\n",
    "        penalty='l2', \n",
    "        dual=False, # M√°s r√°pido para n_samples > n_features\n",
    "        C=best_params.get('svc__C', 1), # Usamos el C √≥ptimo o 1 si no est√°\n",
    "        class_weight='balanced',\n",
    "        random_state=0,\n",
    "        max_iter=5000 \n",
    "    ))\n",
    "])\n",
    "\n",
    "# Inicializamos RFE (Lo envolvemos en un GridSearchCV para encontrar n_features_to_select √≥ptimo)\n",
    "# Probamos desde 1 caracter√≠stica hasta el n√∫mero total de caracter√≠sticas\n",
    "n_features_total = X_train.shape[1]\n",
    "feature_range = list(range(1, n_features_total + 1))\n",
    "\n",
    "rfe_grid_search = GridSearchCV(\n",
    "    estimator=RFE(rfe_base_estimator, step=1),\n",
    "    param_grid={'n_features_to_select': feature_range},\n",
    "    scoring=f1_scorer, # Optimizamos el n√∫mero de caracter√≠sticas basado en F1-Score\n",
    "    cv=5,\n",
    "    verbose=0,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(f\"Iniciando b√∫squeda para el n√∫mero √≥ptimo de caracter√≠sticas (probando 1 a {n_features_total})...\")\n",
    "rfe_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 3. Aplicar la Selecci√≥n √ìptima\n",
    "best_n_features = rfe_grid_search.best_params_['n_features_to_select']\n",
    "print(f\"N√∫mero √ìptimo de Caracter√≠sticas (basado en F1-Score): {best_n_features}\")\n",
    "\n",
    "# Creamos el selector final RFE con el n√∫mero √≥ptimo encontrado\n",
    "rfe_selector_final = RFE(\n",
    "    estimator=rfe_base_estimator,\n",
    "    n_features_to_select=best_n_features,\n",
    "    step=1\n",
    ")\n",
    "rfe_selector_final.fit(X_train, y_train)\n",
    "\n",
    "# Aplicar la Selecci√≥n a los Conjuntos de Datos\n",
    "selected_indices = np.where(rfe_selector_final.support_)[0]\n",
    "X_train_rfe = X_train[:, selected_indices]\n",
    "X_test_rfe = X_test[:, selected_indices]\n",
    "\n",
    "print(f\"Caracter√≠sticas seleccionadas (√≠ndices): {selected_indices}\")\n",
    "print(f\"Dimensiones de los datos de entrenamiento con RFE: {X_train_rfe.shape}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. RE-ENTRENAMIENTO Y EVALUACI√ìN FINAL con SUB-CONJUNTO\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\nRe-entrenando el modelo SVM RBF √≥ptimo con el subconjunto de caracter√≠sticas...\")\n",
    "\n",
    "# Re-inicializamos el modelo RBF √≥ptimo (sin el escalador, ya que X_train_rfe ya estaba escalado)\n",
    "final_svm_rfe = SVC(\n",
    "    kernel=best_params['svc__kernel'],\n",
    "    C=best_params['svc__C'],\n",
    "    gamma=best_params.get('svc__gamma', 'scale'),\n",
    "    probability=True,\n",
    "    class_weight='balanced', # Mantenemos el peso de clase CR√çTICO\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "final_svm_rfe.fit(X_train_rfe, y_train)\n",
    "\n",
    "# Evaluaci√≥n Final en Test\n",
    "y_prob_rfe = final_svm_rfe.predict_proba(X_test_rfe)[:, 1]\n",
    "y_pred_rfe = final_svm_rfe.predict(X_test_rfe)\n",
    "\n",
    "# M√©tricas finales\n",
    "final_metrics_rfe = {\n",
    "    \"accuracy\": accuracy_score(y_test, y_pred_rfe),\n",
    "    \"precision_pos\": precision_score(y_test, y_pred_rfe),\n",
    "    \"recall_pos\": recall_score(y_test, y_pred_rfe),\n",
    "    \"f1_pos\": f1_score(y_test, y_pred_rfe),\n",
    "    \"auc\": roc_auc_score(y_test, y_prob_rfe)\n",
    "}\n",
    "\n",
    "print(\"\\n=========================================================\")\n",
    "print(f\"       ‚úÖ Evaluaci√≥n FINAL con Selecci√≥n de Caracter√≠sticas (RFE)        \")\n",
    "print(\"=========================================================\")\n",
    "print(f\"Arquitectura: SVM {best_params['svc__kernel'].upper()} (Optimizada)\")\n",
    "print(f\"N√∫mero de Caracter√≠sticas Usadas: {best_n_features}\")\n",
    "print(\"\\nMETRICAS EN TEST (RFE):\", final_metrics_rfe)\n",
    "print(\"\\nReporte de Clasificaci√≥n en Test (RFE):\")\n",
    "print(classification_report(y_test, y_pred_rfe))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4056d1fa",
   "metadata": {},
   "source": [
    "Como vemos, los resultados son id√©nticos al SVM realizado antes. Esto indica que tan solo 10 car√°cteristicas del total eran relevantes para el modelo, siendo entonces ruido o irrelevantes las otras"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ML Comercio)",
   "language": "python",
   "name": "mi_entorno_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
